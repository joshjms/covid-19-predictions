{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns \n",
    "import os\n",
    "\n",
    "plt.rc('font', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cases_and_deaths.csv')\n",
    "df = df.fillna(0)\n",
    "df['date'] = pd.to_datetime(df['date']).astype('int64')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take only Indonesia's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['location'] == 'Indonesia']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.xticks(df['date'][::60], rotation=90)\n",
    "plt.plot(df['date'], df['new_cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[['date', 'new_cases']]\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_decomposition = seasonal_decompose(clean_df['new_cases'], model='additive', period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_decomposition.plot().suptitle('Additive Decomposition')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Stationarity\n",
    "\n",
    "result = adfuller(clean_df['new_cases'], autolag='AIC')\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'n_lags: {result[1]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is less than $0.05$ so the data is more or less stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended = clean_df['new_cases'].values - additive_decomposition.trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "ax1.plot(clean_df['new_cases'])\n",
    "ax2.plot(detrended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasonalized = clean_df['new_cases'].values / additive_decomposition.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "ax1.plot(clean_df['new_cases'])\n",
    "ax2.plot(deseasonalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Draw Plot\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\n",
    "plot_acf(clean_df['new_cases'].tolist(), lags=50, ax=axes[0])\n",
    "plot_pacf(clean_df['new_cases'].tolist(), lags=50, ax=axes[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = clean_df['new_cases'].values.astype('float32').reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scaler.fit_transform(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.80\n",
    "\n",
    "train_size = int(len(dataset) * TRAIN_SIZE)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of entries (training set, test set): \" + str((len(train), len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, window_size = 1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size, 0])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and training sets for one-step-ahead regression.\n",
    "window_size = 60\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "print(\"Original training data shape:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "\n",
    "# Reshape the input data into appropriate form for Keras.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"New training data shape:\")\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(input_shape=(1, window_size),\n",
    "               units=window_size,\n",
    "               return_sequences=True, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_Y, epochs=3000, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    pred_scaled = model.predict(X)\n",
    "    pred = scaler.inverse_transform(pred_scaled)\n",
    "    orig_data = scaler.inverse_transform([Y])\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred, pred_scaled)\n",
    "\n",
    "rmse_train, train_predict, train_predict_scaled = predict_and_score(model, train_X, train_Y)\n",
    "rmse_test, test_predict, test_predict_scaled = predict_and_score(model, test_X, test_Y)\n",
    "\n",
    "print(f\"Training RMSE: {rmse_train} RMSE\")\n",
    "print(f\"Test RMSE: {rmse_test} RMSE\")\n",
    "\n",
    "test_predict.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_plot = np.empty_like(dataset)\n",
    "train_predict_plot[:, :] = np.nan\n",
    "train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n",
    "test_predict_plot = np.empty_like(dataset)\n",
    "test_predict_plot[:, :] = np.nan\n",
    "test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(scaler.inverse_transform(dataset), label = \"True value\")\n",
    "plt.plot(train_predict_plot, label = \"Training set prediction\")\n",
    "plt.plot(test_predict_plot, label = \"Test set prediction\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"New COVID Cases\")\n",
    "plt.title(\"Comparison true vs. predicted training / test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predictions\n",
    "\n",
    "def predict(T, X):\n",
    "    X_val=X.reshape(1, 1, window_size)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for t in range(T):\n",
    "        P = model.predict(X_val[-1].reshape(1, 1, window_size))\n",
    "        predictions.append(P[0][0])\n",
    "        new_X_val = X_val[-1][0].reshape(window_size)\n",
    "        new_X_val = new_X_val[1:]\n",
    "        P = P[0].reshape(1)\n",
    "        new_X_val = np.concatenate((new_X_val, P), axis=0)\n",
    "        X_val = np.concatenate((X_val, [[new_X_val]]))\n",
    "\n",
    "    predictions = [predictions]\n",
    "    predictions_scaled = scaler.inverse_transform(predictions)\n",
    "\n",
    "    return predictions, predictions_scaled\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, predictions_scaled = predict(5, test_X[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [round(x) for x in predictions_scaled[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e442552c75236856017fd4037b502e4384752e295518d6aa20e56a6cbbf032e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
